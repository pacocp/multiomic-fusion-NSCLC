{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from scipy import stats\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gene_matrix_CNV.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nan = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nan.to_csv('gene_matrix_CNV_noNA.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentialy expressed Genes with Copy Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('p-values-matrix')\n",
    "os.mkdir('train_degs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Splits_10CV/'\n",
    "for split in range(0,10):\n",
    "    print('{}/{}'.format(split,9))\n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "        \n",
    "    train_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(train_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(val_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(i)\n",
    "\n",
    "    train_final.insert(0, 1)\n",
    "    val_final.insert(0, 1)\n",
    "    df_train = data.iloc[:,train_final]\n",
    "    df_val = data.iloc[:,val_final]\n",
    "    labels_train = df_train.iloc[-1,:].values\n",
    "    labels_train = np.where(labels_train == 'Blood Derived Normal', 'Healthy', labels_train)\n",
    "    labels_train = np.where(labels_train == 'Solid Tissue Normal', 'Healthy', labels_train)\n",
    "\n",
    "    hlt_idx = np.where(labels_train == 'Healthy')[0]\n",
    "    luad_idx = np.where(labels_train == 'LUAD')[0]\n",
    "    lusc_idx = np.where(labels_train == 'LUSC')[0]\n",
    "    \n",
    "    # p-values and means\n",
    "    p_value_hltluad = []\n",
    "    p_value_hltlusc = []\n",
    "    p_value_luscluad = []\n",
    "    mean_dif_hltluad = []\n",
    "    mean_dif_hltlusc = []\n",
    "    mean_dif_luscluad = []\n",
    "    for _, row in tqdm(df_train.iterrows()):\n",
    "        if row[0] == 'X':\n",
    "            continue\n",
    "        comp_counter = 0\n",
    "        \n",
    "        hlt = row[hlt_idx].to_numpy(dtype='float')\n",
    "        luad = row[luad_idx].to_numpy(dtype='float')\n",
    "        lusc = row[lusc_idx].to_numpy(dtype='float')\n",
    "\n",
    "        stats_hltluad = stats.ttest_ind(hlt,luad,equal_var=False)\n",
    "        stats_hltlusc = stats.ttest_ind(hlt,lusc,equal_var=False)\n",
    "        stats_luscluad = stats.ttest_ind(lusc,luad,equal_var=False)\n",
    "\n",
    "        mean_dif_hltluad.append(np.abs(np.mean(hlt) - np.mean(luad)))\n",
    "        mean_dif_hltlusc.append(np.abs(np.mean(hlt) - np.mean(lusc)))\n",
    "        mean_dif_luscluad.append(np.abs(np.mean(lusc) - np.mean(luad)))\n",
    "\n",
    "        p_value_hltluad.append(stats_hltluad.pvalue)\n",
    "        p_value_hltlusc.append(stats_hltlusc.pvalue)\n",
    "        p_value_luscluad.append(stats_luscluad.pvalue)\n",
    "    \n",
    "    p_values_df = pd.DataFrame()\n",
    "    p_values_df['gene_name'] = df_train['gene_name'].values[:-1]\n",
    "    p_values_df['HltLusc'] = p_value_hltlusc\n",
    "    p_values_df['HltLuad'] = p_value_hltluad\n",
    "    p_values_df['LuscLuad'] = p_value_luscluad\n",
    "    p_values_df['MeanHltLuad'] = mean_dif_hltluad\n",
    "    p_values_df['MeanHltLusc'] = mean_dif_hltlusc\n",
    "    p_values_df['MeanLuscLuad'] = mean_dif_luscluad\n",
    "\n",
    "    p_values_df.to_csv('p-values-matrix/p_values_train'+str(split)+'.csv', index=False)\n",
    "    decpgs = []\n",
    "    for _, row in tqdm(p_values_df.iterrows()):\n",
    "        comp_counter = 0\n",
    "        if row['HltLuad'] <= 0.001/3 and row['MeanHltLuad'] >= 0.4:\n",
    "                comp_counter += 1\n",
    "        if row['HltLusc'] <= 0.001/3 and row['MeanHltLusc'] >= 0.4:\n",
    "            comp_counter += 1\n",
    "        if row['LuscLuad'] <= 0.001/3 and row['MeanLuscLuad'] >= 0.4:\n",
    "            comp_counter += 1\n",
    "\n",
    "        if comp_counter == 2:\n",
    "            decpgs.append(row[0])\n",
    "    \n",
    "    decpgs.append('X')\n",
    "    \n",
    "    train_degs = df_train.loc[df_train['gene_name'].isin(decpgs)]\n",
    "    train_degs.to_csv('train_degs/DEGs_CNV_train'+str(split)+'_p0-001_cov2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "for file in sorted(glob('train_degs/*.csv')):\n",
    "    train_data = pd.read_csv(file)\n",
    "    train_data = train_data.replace('Blood Derived Normal', 'Healthy')\n",
    "    train_data = train_data.replace('Solid Tissue Normal', 'Healthy')\n",
    "    train_data = train_data.replace('X', 'Label')\n",
    "    name = file.split('/')[-1]\n",
    "    train_data.to_csv('train_degs2/'+name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('train_degs2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "classes = np.array(['Healthy', 'LUAD', 'LUSC'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Splits_10CV/'\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "train_F1 = []\n",
    "test_F1 = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(10*'-')\n",
    "    print('Split {}/{}'.format(i,10))\n",
    "    print(10*'-')\n",
    "    \n",
    "    data = pd.read_csv('mrmrDEGs/mrmrDEGs_LC_CNV_3classes_split'+str(i)+'.csv')\n",
    "    \n",
    "    train_f = open(path+'train_'+str(i)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(i)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(i)\n",
    "\n",
    "    #train_final.insert(0, 1)\n",
    "    #val_final.insert(0, 1)\n",
    "    df_train = data.iloc[train_final,]\n",
    "    df_val = data.iloc[val_final,]\n",
    "\n",
    "    case_ids_val = df_val['Case_IDs']\n",
    "    val_df_all = data_all[case_ids_val]\n",
    "    y_val = val_df_all.iloc[-1,:].values\n",
    "    y_val = np.where(y_val == 'Blood Derived Normal', 'Healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Solid Tissue Normal', 'Healthy', y_val)\n",
    "\n",
    "    case_ids_train = df_train['Case_IDs']\n",
    "    train_df_all = data_all[case_ids_train]\n",
    "    y_train = train_df_all.iloc[-1,:].values\n",
    "    y_train = np.where(y_train == 'Blood Derived Normal', 'Healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Solid Tissue Normal', 'Healthy', y_train)\n",
    "    \n",
    "    x_train = df_train.iloc[:,1:7].values\n",
    "    x_val = df_val.iloc[:,1:7].values\n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "    clf = GridSearchCV(\n",
    "                    SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "    print(clf.best_params_)\n",
    "    best_params = clf.best_params_\n",
    "    train_preds = clf.predict(x_train)\n",
    "    corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "    train_acc = (corrects / x_train.shape[0]) * 100\n",
    "    train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted', labels=[1, 0, 2])\n",
    "    train_accs.append(train_acc)\n",
    "    train_F1.append(train_f1)\n",
    "    print('SVM train acc: {}'.format(train_acc))\n",
    "    print('SVM train F1: {}'.format(train_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2]))\n",
    "    \n",
    "    svm_ = SVC(**best_params)\n",
    "    #print(clf.best_params_)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    test_preds = clf.predict(x_val)\n",
    "    corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "    test_acc = (corrects / x_val.shape[0]) * 100\n",
    "    test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted', labels=[1, 0, 2])\n",
    "    test_accs.append(test_acc)\n",
    "    test_F1.append(test_f1)\n",
    "    print('SVM test acc: {}'.format(test_acc))\n",
    "    print('SVM test F1: {}'.format(test_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds,labels=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1)*100,np.std(train_F1)*100))\n",
    "print(10*'-')\n",
    "print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1)*100,np.std(test_F1)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:7].values\n",
    "x_val = df_val.iloc[:,1:7].values\n",
    "y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "y_val_ohe = ohe.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "clf = GridSearchCV(\n",
    "                SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "            )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "print(clf.best_params_)\n",
    "best_params = clf.best_params_\n",
    "train_preds = clf.predict(x_train)\n",
    "corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "train_acc = (corrects / x_train.shape[0]) * 100\n",
    "print('kNN train acc: {}'.format(train_acc))\n",
    "print('CM \\n')\n",
    "print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['LUAD', 'Healthy', 'LUSC'])\n",
    "disp.plot(cmap= \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ = SVC(**best_params)\n",
    "#print(clf.best_params_)\n",
    "x_val = scaler.transform(x_val)\n",
    "test_preds = clf.predict(x_val)\n",
    "corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "test_acc = (corrects / x_val.shape[0]) * 100\n",
    "print('kNN test acc: {}'.format(test_acc))\n",
    "print('CM \\n')\n",
    "print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds,labels=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val_ohe.argmax(axis=1), test_preds, labels=[1, 0, 2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['LUAD', 'Healthy', 'LUSC'])\n",
    "disp.plot(cmap= \"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE feature visualiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x_val)\n",
    "\n",
    "hlt = np.where(y_val == 'Healthy')[0]\n",
    "luad = np.where(y_val == 'LUAD')[0]\n",
    "lusc = np.where(y_val == 'LUSC')[0]\n",
    "\n",
    "X_embedded_hlt = X_embedded[hlt,:]\n",
    "X_embedded_luad = X_embedded[luad,:]\n",
    "X_embedded_lusc = X_embedded[lusc,:]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_embedded_hlt[:, 0], X_embedded_hlt[:, 1], c='blue', label='HLT')\n",
    "plt.scatter(X_embedded_luad[:, 0], X_embedded_luad[:, 1], c='green', label='LUAD')\n",
    "plt.scatter(X_embedded_lusc[:, 0], X_embedded_lusc[:, 1], c='red', label='LUSC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
