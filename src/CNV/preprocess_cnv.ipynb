{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from scipy import stats\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gene_matrix_CNV.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nan = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nan.to_csv('gene_matrix_CNV_noNA.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentialy expressed Genes with Copy Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('p-values-matrix')\n",
    "#os.mkdir('train_degs2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = 'Splits_10CV/'\n",
    "for split in range(0,10):\n",
    "    print('{}/{}'.format(split,9))\n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "        \n",
    "    train_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(train_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(val_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(i)\n",
    "\n",
    "    train_final.insert(0, 1)\n",
    "    val_final.insert(0, 1)\n",
    "    df_train = data.iloc[:,train_final]\n",
    "    df_val = data.iloc[:,val_final]\n",
    "    labels_train = df_train.iloc[-1,:].values\n",
    "    no_BDN = np.where(labels_train != 'Blood Derived Normal')[0]\n",
    "    no_BDN = no_BDN.tolist()\n",
    "    df_train = df_train.iloc[:,no_BDN]\n",
    "    labels_train = labels_train[no_BDN]\n",
    "    #labels_train = np.where(labels_train == 'Blood Derived Normal', 'Healthy', labels_train)\n",
    "    labels_train = np.where(labels_train == 'Solid Tissue Normal', 'Healthy', labels_train)\n",
    "\n",
    "    hlt_idx = np.where(labels_train == 'Healthy')[0]\n",
    "    luad_idx = np.where(labels_train == 'LUAD')[0]\n",
    "    lusc_idx = np.where(labels_train == 'LUSC')[0]\n",
    "    \n",
    "    # p-values and means\n",
    "    p_value_hltluad = []\n",
    "    p_value_hltlusc = []\n",
    "    p_value_luscluad = []\n",
    "    mean_dif_hltluad = []\n",
    "    mean_dif_hltlusc = []\n",
    "    mean_dif_luscluad = []\n",
    "    for _, row in tqdm(df_train.iterrows()):\n",
    "        if row[0] == 'X':\n",
    "            continue\n",
    "        comp_counter = 0\n",
    "        \n",
    "        hlt = row[hlt_idx].to_numpy(dtype='float')\n",
    "        luad = row[luad_idx].to_numpy(dtype='float')\n",
    "        lusc = row[lusc_idx].to_numpy(dtype='float')\n",
    "\n",
    "        stats_hltluad = stats.ttest_ind(hlt,luad,equal_var=False)\n",
    "        stats_hltlusc = stats.ttest_ind(hlt,lusc,equal_var=False)\n",
    "        stats_luscluad = stats.ttest_ind(lusc,luad,equal_var=False)\n",
    "\n",
    "        mean_dif_hltluad.append(np.abs(np.mean(hlt) - np.mean(luad)))\n",
    "        mean_dif_hltlusc.append(np.abs(np.mean(hlt) - np.mean(lusc)))\n",
    "        mean_dif_luscluad.append(np.abs(np.mean(lusc) - np.mean(luad)))\n",
    "\n",
    "        p_value_hltluad.append(stats_hltluad.pvalue)\n",
    "        p_value_hltlusc.append(stats_hltlusc.pvalue)\n",
    "        p_value_luscluad.append(stats_luscluad.pvalue)\n",
    "    \n",
    "    p_values_df = pd.DataFrame()\n",
    "    p_values_df['gene_name'] = df_train['gene_name'].values[:-1]\n",
    "    p_values_df['HltLusc'] = p_value_hltlusc\n",
    "    p_values_df['HltLuad'] = p_value_hltluad\n",
    "    p_values_df['LuscLuad'] = p_value_luscluad\n",
    "    p_values_df['MeanHltLuad'] = mean_dif_hltluad\n",
    "    p_values_df['MeanHltLusc'] = mean_dif_hltlusc\n",
    "    p_values_df['MeanLuscLuad'] = mean_dif_luscluad\n",
    "\n",
    "    p_values_df.to_csv('p-values-matrix/p_values_train'+str(split)+'_noBDN.csv', index=False)\n",
    "    decpgs = []\n",
    "    for _, row in tqdm(p_values_df.iterrows()):\n",
    "        comp_counter = 0\n",
    "        if row['HltLuad'] <= 0.001/3 and row['MeanHltLuad'] >= 0.1:\n",
    "                comp_counter += 1\n",
    "        if row['HltLusc'] <= 0.001/3 and row['MeanHltLusc'] >= 0.1:\n",
    "            comp_counter += 1\n",
    "        if row['LuscLuad'] <= 0.001/3 and row['MeanLuscLuad'] >= 0.1:\n",
    "            comp_counter += 1\n",
    "\n",
    "        if comp_counter == 3:\n",
    "            decpgs.append(row[0])\n",
    "    \n",
    "    decpgs.append('X')\n",
    "    \n",
    "    train_degs = df_train.loc[df_train['gene_name'].isin(decpgs)]\n",
    "    train_degs = train_degs.replace('Solid Tissue Normal', 'Healthy')\n",
    "    train_degs = train_degs.replace('X', 'Label')\n",
    "    train_degs.to_csv('train_degs2/DEGs_CNV_train'+str(split)+'_p0-001_cov3_noBDN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "for file in tqdm(sorted(glob('train_degs/*cov3.csv'))):\n",
    "    train_data = pd.read_csv(file)\n",
    "    train_data = train_data.replace('Blood Derived Normal', 'Healthy')\n",
    "    train_data = train_data.replace('Solid Tissue Normal', 'Healthy')\n",
    "    train_data = train_data.replace('X', 'Label')\n",
    "    name = file.split('/')[-1]\n",
    "    train_data.to_csv('train_degs2/'+name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('train_degs2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "import xgboost as xgb\n",
    "classes = np.array(['healthy', 'adeno', 'squa'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('results_excels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(np.array(['adeno']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set(x, y, classes, percentage = 0.1):\n",
    "    np.random.seed(42)  \n",
    "    x_train = np.array([]).reshape(0,x.shape[1])\n",
    "    y_train = np.array([]).reshape(0,y.shape[1])\n",
    "    x_val = np.array([]).reshape(0,x.shape[1])\n",
    "    y_val = np.array([]).reshape(0,y.shape[1])\n",
    "    for c in classes:\n",
    "        indexes = np.where(y.argmax(axis=1) == c)[0]\n",
    "        np.random.shuffle(indexes)\n",
    "        len_val = int(percentage * len(indexes))\n",
    "        len_train = len(indexes) - len_val\n",
    "        index_train = indexes[0:len_train]\n",
    "        index_val = indexes[len_train:]\n",
    "        x_train = np.concatenate([x_train, x[index_train,...]], axis=0)\n",
    "        y_train = np.concatenate([y_train, y[index_train]], axis=0)\n",
    "        x_val = np.concatenate([x_val, x[index_val,...]], axis=0)\n",
    "        y_val = np.concatenate([y_val, y[index_val]], axis=0)\n",
    "    \n",
    "    index_train = list(range(x_train.shape[0]))\n",
    "    index_val = list(range(x_val.shape[0]))\n",
    "    np.random.shuffle(index_train)\n",
    "    np.random.shuffle(index_val)\n",
    "    \n",
    "    return x_train[index_train,...],y_train[index_train], x_val[index_val,...], y_val[index_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from tqdm.notebook import tqdm\n",
    "path = 'Splits_10CV/'\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "train_F1 = []\n",
    "test_F1 = []\n",
    "\n",
    "n_genes = 12\n",
    "writer_test = pd.ExcelWriter('results_excels/CNV_'+str(n_genes)+'gen_XGBOOST_test.xlsx', engine='openpyxl') \n",
    "writer_train = pd.ExcelWriter('results_excels/CNV_'+str(n_genes)+'gen_XGBOOST_train.xlsx', engine='openpyxl') \n",
    "all_labels = data_all.iloc[-1,:]\n",
    "for split in tqdm(range(10)):\n",
    "    print(10*'-')\n",
    "    print('Split {}/{}'.format(split,10))\n",
    "    print(10*'-')\n",
    "    \n",
    "    print('Data read...')\n",
    "    data = pd.read_csv('mrmrDEGs/mrmrDEGs_LC_CNV_3classes_p0-001_m0-1_cov3_split'+str(split)+'.csv')\n",
    "    \n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for j in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[j])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(j)\n",
    "\n",
    "    #train_final.insert(0, 1)\n",
    "    #val_final.insert(0, 1)\n",
    "    df_train = data.iloc[train_final,]\n",
    "    df_val = data.iloc[val_final,]\n",
    "\n",
    "    case_ids_val = df_val['Case_IDs']\n",
    "    #val_df_all = data_all[case_ids_val]\n",
    "    y_val = all_labels[case_ids_val].values\n",
    "    y_val = np.where(y_val == 'Blood Derived Normal', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Solid Tissue Normal', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'LUAD', 'adeno', y_val)\n",
    "    y_val = np.where(y_val == 'LUSC', 'squa', y_val)\n",
    "    \n",
    "    case_ids_train = df_train['Case_IDs']\n",
    "    #train_df_all = data_all[case_ids_train]\n",
    "    y_train = all_labels[case_ids_train].values\n",
    "    y_train = np.where(y_train == 'Blood Derived Normal', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Solid Tissue Normal', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'LUAD', 'adeno', y_train)\n",
    "    y_train = np.where(y_train == 'LUSC', 'squa', y_train)\n",
    "    \n",
    "    x_train = df_train.iloc[:,1:n_genes+1].values\n",
    "    x_val = df_val.iloc[:,1:n_genes+1].values\n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "    print('End data read...')\n",
    "    \n",
    "    '''\n",
    "    print('Svm training...')\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "    clf = GridSearchCV(\n",
    "                    SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                )\n",
    "    '''\n",
    "    tuned_parameters = [{'max_depth': [2, 4, 6, 8],\n",
    "                            'n_estimators': [20, 30, 50, 100, 200],\n",
    "                         'alpha': [0,0.1,0.2,0.3]}]\n",
    "    \n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "                    xgb.XGBClassifier(n_jobs=1,use_label_encoder=False,verbosity = 0, random_state=42), tuned_parameters, \n",
    "                    scoring='accuracy'\n",
    "                )\n",
    "    classes_ = [0,1,2]\n",
    "    x_train_new, y_train_ohe_new, x_val_early, y_val_early = get_val_set(x_train, y_train_ohe, classes_, percentage = 0.1)\n",
    "    scaler = StandardScaler()\n",
    "    x_train_new = scaler.fit_transform(x_train_new)\n",
    "    eval_set=[(scaler.transform(x_val_early), y_val_early.argmax(axis=1))]\n",
    "    clf.fit(x_train_new, y_train_ohe_new.argmax(axis=1), early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    print(clf.best_params_)\n",
    "    best_params = clf.best_params_\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    train_preds = clf.predict(x_train)\n",
    "    corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "    train_acc = (corrects / x_train.shape[0]) * 100\n",
    "    train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted')\n",
    "    train_accs.append(train_acc)\n",
    "    train_F1.append(train_f1)\n",
    "    train_probs = clf.predict_proba(x_train)\n",
    "    print('SVM train acc: {}'.format(train_acc))\n",
    "    print('SVM train F1: {}'.format(train_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds))\n",
    "    \n",
    "    #svm_ = SVC(**best_params)\n",
    "    #print(clf.best_params_)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    test_preds = clf.predict(x_val)\n",
    "    corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "    test_acc = (corrects / x_val.shape[0]) * 100\n",
    "    test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted')\n",
    "    test_accs.append(test_acc)\n",
    "    test_F1.append(test_f1)\n",
    "    test_probs = clf.predict_proba(x_val)\n",
    "    print('SVM test acc: {}'.format(test_acc))\n",
    "    print('SVM test F1: {}'.format(test_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds))\n",
    "    \n",
    "    print(\"Saving SVM predictions... \\n\")\n",
    "    \n",
    "    sheet_name = 'split_'+str(split)\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_val\n",
    "    data['Preds'] = test_preds\n",
    "    data['Prob LUAD'] = test_probs[:, 0]\n",
    "    data['Prob HLT'] = test_probs[:, 1]\n",
    "    data['Prob LUSC'] = test_probs[:, 2]\n",
    "    data['Real'] = y_val_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_test, sheet_name = sheet_name)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_train\n",
    "    data['Preds'] = train_preds\n",
    "    data['Prob LUAD'] = train_probs[:, 0]\n",
    "    data['Prob HLT'] = train_probs[:, 1]\n",
    "    data['Prob LUSC'] = train_probs[:, 2]\n",
    "    data['Real'] = y_train_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_train, sheet_name=sheet_name)\n",
    "\n",
    "writer_train.close()\n",
    "writer_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1)*100,np.std(train_F1)*100))\n",
    "print(10*'-')\n",
    "print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1)*100,np.std(test_F1)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1)*100,np.std(train_F1)*100))\n",
    "print(10*'-')\n",
    "print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1)*100,np.std(test_F1)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm2\n",
    "# All range of genes results\n",
    "path = 'Splits_10CV/'\n",
    "\n",
    "\n",
    "range_genes = 16\n",
    "all_labels = data_all.iloc[-1,:]\n",
    "pbar = tqdm2(range(1,range_genes))\n",
    "global_train_accs = {'mean':[],'std':[]}\n",
    "global_test_accs = {'mean':[],'std':[]}\n",
    "global_train_f1 = {'mean':[],'std':[]}\n",
    "global_test_f1 = {'mean':[],'std':[]}\n",
    "for n_genes in pbar:\n",
    "    pbar.set_description('Working with {} genes'.format(n_genes))\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    train_F1 = []\n",
    "    test_F1 = []\n",
    "    for i in range(10):\n",
    "        print(10*'-')\n",
    "        print('Split {}/{}'.format(i,10))\n",
    "        print(10*'-')\n",
    "\n",
    "        print('Data read...')\n",
    "        data = pd.read_csv('mrmrDEGs/mrmrDEGs_LC_CNV_3classes_p0-001_m0-1_cov3_split'+str(i)+'.csv')\n",
    "\n",
    "        train_f = open(path+'train_'+str(i)+'.txt', 'r')\n",
    "        train_caseids = train_f.readlines()\n",
    "        train_f.close()\n",
    "        val_f = open(path+'val_'+str(i)+'.txt', 'r')\n",
    "        val_caseids = val_f.readlines()\n",
    "        val_f.close()\n",
    "\n",
    "        train_cids = []\n",
    "        for cid in train_caseids:\n",
    "            train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "        val_cids = []\n",
    "        for cid in val_caseids:\n",
    "            val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "        train_final = []\n",
    "        for i in range(len(list(data['Case_IDs'].values))):\n",
    "            resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "            if resu:\n",
    "                if resu.group(0) != '':\n",
    "                    train_final.append(i)\n",
    "\n",
    "        val_final = []\n",
    "        for i in range(len(list(data['Case_IDs'].values))):\n",
    "            resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[i])\n",
    "            if resu:\n",
    "                if resu.group(0) != '':\n",
    "                    val_final.append(i)\n",
    "\n",
    "        #train_final.insert(0, 1)\n",
    "        #val_final.insert(0, 1)\n",
    "        df_train = data.iloc[train_final,]\n",
    "        df_val = data.iloc[val_final,]\n",
    "\n",
    "        case_ids_val = df_val['Case_IDs']\n",
    "        #val_df_all = data_all[case_ids_val]\n",
    "        y_val = all_labels[case_ids_val].values\n",
    "        y_val = np.where(y_val == 'Blood Derived Normal', 'Healthy', y_val)\n",
    "        y_val = np.where(y_val == 'Solid Tissue Normal', 'Healthy', y_val)\n",
    "\n",
    "        case_ids_train = df_train['Case_IDs']\n",
    "        #train_df_all = data_all[case_ids_train]\n",
    "        y_train = all_labels[case_ids_train].values\n",
    "        y_train = np.where(y_train == 'Blood Derived Normal', 'Healthy', y_train)\n",
    "        y_train = np.where(y_train == 'Solid Tissue Normal', 'Healthy', y_train)\n",
    "\n",
    "        x_train = df_train.iloc[:,1:n_genes+1].values\n",
    "        x_val = df_val.iloc[:,1:n_genes+1].values\n",
    "        y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "        y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "        print('End data read...')\n",
    "\n",
    "        print('Svm training...')\n",
    "        tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                            'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "        clf = GridSearchCV(\n",
    "                        SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                    )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "        print(clf.best_params_)\n",
    "        best_params = clf.best_params_\n",
    "        train_preds = clf.predict(x_train)\n",
    "        corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "        train_acc = (corrects / x_train.shape[0]) * 100\n",
    "        train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted', labels=[1, 0, 2])\n",
    "        train_accs.append(train_acc)\n",
    "        train_F1.append(train_f1*100)\n",
    "        print('SVM train acc: {}'.format(train_acc))\n",
    "        print('SVM train F1: {}'.format(train_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2]))\n",
    "\n",
    "        svm_ = SVC(**best_params)\n",
    "        #print(clf.best_params_)\n",
    "        x_val = scaler.transform(x_val)\n",
    "        test_preds = clf.predict(x_val)\n",
    "        corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "        test_acc = (corrects / x_val.shape[0]) * 100\n",
    "        test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted', labels=[1, 0, 2])\n",
    "        test_accs.append(test_acc)\n",
    "        test_F1.append(test_f1*100)\n",
    "        print('SVM test acc: {}'.format(test_acc))\n",
    "        print('SVM test F1: {}'.format(test_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds,labels=[1, 0, 2]))\n",
    "    print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "    print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1),np.std(train_F1)))\n",
    "    print(10*'-')\n",
    "    print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "    print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1),np.std(test_F1)))\n",
    "    \n",
    "    global_train_accs['mean'].append(np.mean(train_accs))\n",
    "    global_test_accs['mean'].append(np.mean(test_accs))\n",
    "    global_train_f1['mean'].append(np.mean(train_F1))\n",
    "    global_test_f1['mean'].append(np.mean(test_F1))\n",
    "    global_train_accs['std'].append(np.std(train_accs))\n",
    "    global_test_accs['std'].append(np.std(test_accs))\n",
    "    global_train_f1['std'].append(np.std(train_F1))\n",
    "    global_test_f1['std'].append(np.std(test_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results for range of genes\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('Accuracy CNV')\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('#genes')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.plot(list(range(1,16)), global_test_accs['mean'], color=\"blue\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('std')  # we already handled the x-label with ax1\n",
    "ax2.plot(list(range(1,16)), global_test_accs['std'], color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig('plots/acc_range_p0-001_m0-1_cov3.png', format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Plot results for range of genes\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('F1 CNV')\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('#genes')\n",
    "ax1.set_ylabel('F1-Score')\n",
    "ax1.plot(list(range(1,16)), global_test_f1['mean'], color=\"blue\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('std')  # we already handled the x-label with ax1\n",
    "ax2.plot(list(range(1,16)), global_test_f1['std'], color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig('plots/f1_range_p0-001_m0-1_cov3.png', format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:7].values\n",
    "x_val = df_val.iloc[:,1:7].values\n",
    "y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "y_val_ohe = ohe.transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "clf = GridSearchCV(\n",
    "                SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "            )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "print(clf.best_params_)\n",
    "best_params = clf.best_params_\n",
    "train_preds = clf.predict(x_train)\n",
    "corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "train_acc = (corrects / x_train.shape[0]) * 100\n",
    "print('kNN train acc: {}'.format(train_acc))\n",
    "print('CM \\n')\n",
    "print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['LUAD', 'Healthy', 'LUSC'])\n",
    "disp.plot(cmap= \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ = SVC(**best_params)\n",
    "#print(clf.best_params_)\n",
    "x_val = scaler.transform(x_val)\n",
    "test_preds = clf.predict(x_val)\n",
    "corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "test_acc = (corrects / x_val.shape[0]) * 100\n",
    "print('kNN test acc: {}'.format(test_acc))\n",
    "print('CM \\n')\n",
    "print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds,labels=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val_ohe.argmax(axis=1), test_preds, labels=[1, 0, 2])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['LUAD', 'Healthy', 'LUSC'])\n",
    "disp.plot(cmap= \"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE feature visualiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x_val)\n",
    "\n",
    "hlt = np.where(y_val == 'Healthy')[0]\n",
    "luad = np.where(y_val == 'LUAD')[0]\n",
    "lusc = np.where(y_val == 'LUSC')[0]\n",
    "\n",
    "X_embedded_hlt = X_embedded[hlt,:]\n",
    "X_embedded_luad = X_embedded[luad,:]\n",
    "X_embedded_lusc = X_embedded[lusc,:]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_embedded_hlt[:, 0], X_embedded_hlt[:, 1], c='blue', label='HLT')\n",
    "plt.scatter(X_embedded_luad[:, 0], X_embedded_luad[:, 1], c='green', label='LUAD')\n",
    "plt.scatter(X_embedded_lusc[:, 0], X_embedded_lusc[:, 1], c='red', label='LUSC')\n",
    "plt.legend()\n",
    "plt.savefig('plots/tsne_lastfold_cov2.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with cov == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Splits_10CV/'\n",
    "for split in range(0,10):\n",
    "    print('{}/{}'.format(split,9))\n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "        \n",
    "    train_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(train_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(val_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(i)\n",
    "\n",
    "    train_final.insert(0, 1)\n",
    "    val_final.insert(0, 1)\n",
    "    df_train = data.iloc[:,train_final]\n",
    "    df_val = data.iloc[:,val_final]\n",
    "    labels_train = df_train.iloc[-1,:].values\n",
    "    labels_train = np.where(labels_train == 'Blood Derived Normal', 'Healthy', labels_train)\n",
    "    labels_train = np.where(labels_train == 'Solid Tissue Normal', 'Healthy', labels_train)\n",
    "\n",
    "    p_values_df = pd.read_csv('p-values-matrix/p_values_train'+str(split)+'.csv')\n",
    "    decpgs = []\n",
    "    for _, row in tqdm(p_values_df.iterrows()):\n",
    "        comp_counter = 0\n",
    "        if row['HltLuad'] <= 0.001/3 and row['MeanHltLuad'] >= 0.2:\n",
    "                comp_counter += 1\n",
    "        if row['HltLusc'] <= 0.001/3 and row['MeanHltLusc'] >= 0.2:\n",
    "            comp_counter += 1\n",
    "        if row['LuscLuad'] <= 0.001/3 and row['MeanLuscLuad'] >= 0.2:\n",
    "            comp_counter += 1\n",
    "        \n",
    "        if comp_counter >= 1:\n",
    "            decpgs.append(row[0])\n",
    "    \n",
    "    decpgs.append('X')\n",
    "\n",
    "    train_degs = df_train.loc[df_train['gene_name'].isin(decpgs)]\n",
    "    train_degs.to_csv('train_degs2/DEGs_CNV_train'+str(split)+'_p0-001_m0-2_cov1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ML with noBDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('gene_matrix_CNV_noNA.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "classes = np.array(['healthy', 'adeno', 'squa'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))\n",
    "ohe.transform(np.array(['adeno']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "path = 'Splits_10CV/'\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "train_F1 = []\n",
    "test_F1 = []\n",
    "\n",
    "n_genes = 9\n",
    "writer_test = pd.ExcelWriter('results_excels/CNV_'+str(n_genes)+'gen_noBDN_test.xlsx', engine='openpyxl') \n",
    "writer_train = pd.ExcelWriter('results_excels/CNV_'+str(n_genes)+'gen_noBDN_train.xlsx', engine='openpyxl') \n",
    "all_labels = data_all.iloc[-1,:]\n",
    "for split in range(10):\n",
    "    print(10*'-')\n",
    "    print('Split {}/{}'.format(split,10))\n",
    "    print(10*'-')\n",
    "    \n",
    "    print('Data read...')\n",
    "    data = pd.read_csv('mrmrDEGs/mrmrDEGs_LC_CNV_3classes_p0-001_m0-1_cov3_split'+str(split)+'_noBDN.csv')\n",
    "    \n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for j in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[j])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(j)\n",
    "\n",
    "    #train_final.insert(0, 1)\n",
    "    #val_final.insert(0, 1)\n",
    "    df_train = data.iloc[train_final,]\n",
    "    df_val = data.iloc[val_final,]\n",
    "    \n",
    "    #val_df_all = data_all[case_ids_val]\n",
    "    case_ids_val = df_val['Case_IDs']\n",
    "    y_val = all_labels[case_ids_val].values\n",
    "    no_BDN_val = np.where(y_val != 'Blood Derived Normal')[0]\n",
    "    no_BDN_val = no_BDN_val.tolist()\n",
    "    df_val = df_val.iloc[no_BDN_val,:]\n",
    "    y_val = y_val[no_BDN_val]\n",
    "    case_ids_val = case_ids_val.iloc[no_BDN_val]\n",
    "\n",
    "    #y_val = np.where(y_val == 'Blood Derived Normal', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Solid Tissue Normal', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'LUAD', 'adeno', y_val)\n",
    "    y_val = np.where(y_val == 'LUSC', 'squa', y_val)\n",
    "    \n",
    "    #train_df_all = data_all[case_ids_train]\n",
    "    case_ids_train = df_train['Case_IDs']\n",
    "    y_train = all_labels[case_ids_train].values\n",
    "    no_BDN_train = np.where(y_train != 'Blood Derived Normal')[0]\n",
    "    no_BDN_train = no_BDN_train.tolist()\n",
    "    df_train = df_train.iloc[no_BDN_train,:]\n",
    "    y_train = y_train[no_BDN_train]\n",
    "    case_ids_train = case_ids_train.iloc[no_BDN_train]\n",
    "    \n",
    "    #y_train = np.where(y_train == 'Blood Derived Normal', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Solid Tissue Normal', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'LUAD', 'adeno', y_train)\n",
    "    y_train = np.where(y_train == 'LUSC', 'squa', y_train)\n",
    "    \n",
    "    x_train = df_train.iloc[:,1:n_genes+1].values\n",
    "    x_val = df_val.iloc[:,1:n_genes+1].values\n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "    print('End data read...')\n",
    "    \n",
    "    print('Svm training...')\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "    clf = GridSearchCV(\n",
    "                    SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "    print(clf.best_params_)\n",
    "    best_params = clf.best_params_\n",
    "    train_preds = clf.predict(x_train)\n",
    "    corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "    train_acc = (corrects / x_train.shape[0]) * 100\n",
    "    train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted')\n",
    "    train_accs.append(train_acc)\n",
    "    train_F1.append(train_f1)\n",
    "    train_probs = clf.predict_proba(x_train)\n",
    "    print('SVM train acc: {}'.format(train_acc))\n",
    "    print('SVM train F1: {}'.format(train_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds))\n",
    "    \n",
    "    svm_ = SVC(**best_params)\n",
    "    #print(clf.best_params_)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    test_preds = clf.predict(x_val)\n",
    "    corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "    test_acc = (corrects / x_val.shape[0]) * 100\n",
    "    test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted')\n",
    "    test_accs.append(test_acc)\n",
    "    test_F1.append(test_f1)\n",
    "    test_probs = clf.predict_proba(x_val)\n",
    "    print('SVM test acc: {}'.format(test_acc))\n",
    "    print('SVM test F1: {}'.format(test_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds))\n",
    "    \n",
    "    print(\"Saving SVM predictions... \\n\")\n",
    "    \n",
    "    sheet_name = 'split_'+str(split)\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_val\n",
    "    data['Preds'] = test_preds\n",
    "    data['Prob LUAD'] = test_probs[:, 0]\n",
    "    data['Prob HLT'] = test_probs[:, 1]\n",
    "    data['Prob LUSC'] = test_probs[:, 2]\n",
    "    data['Real'] = y_val_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_test, sheet_name = sheet_name)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_train\n",
    "    data['Preds'] = train_preds\n",
    "    data['Prob LUAD'] = train_probs[:, 0]\n",
    "    data['Prob HLT'] = train_probs[:, 1]\n",
    "    data['Prob LUSC'] = train_probs[:, 2]\n",
    "    data['Real'] = y_train_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_train, sheet_name=sheet_name)\n",
    "\n",
    "writer_test.close()\n",
    "writer_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1)*100,np.std(train_F1)*100))\n",
    "print(10*'-')\n",
    "print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1)*100,np.std(test_F1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test better number of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm2\n",
    "# All range of genes results\n",
    "path = 'Splits_10CV/'\n",
    "\n",
    "\n",
    "range_genes = 16\n",
    "all_labels = data_all.iloc[-1,:]\n",
    "pbar = tqdm2(range(1,range_genes))\n",
    "global_train_accs = {'mean':[],'std':[]}\n",
    "global_test_accs = {'mean':[],'std':[]}\n",
    "global_train_f1 = {'mean':[],'std':[]}\n",
    "global_test_f1 = {'mean':[],'std':[]}\n",
    "for n_genes in pbar:\n",
    "    pbar.set_description('Working with {} genes'.format(n_genes))\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    train_F1 = []\n",
    "    test_F1 = []\n",
    "    for split in range(10):\n",
    "        print(10*'-')\n",
    "        print('Split {}/{}'.format(split,10))\n",
    "        print(10*'-')\n",
    "\n",
    "        print('Data read...')\n",
    "        data = pd.read_csv('mrmrDEGs/mrmrDEGs_LC_CNV_3classes_p0-001_m0-1_cov3_split'+str(split)+'_noBDN.csv')\n",
    "\n",
    "        train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "        train_caseids = train_f.readlines()\n",
    "        train_f.close()\n",
    "        val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "        val_caseids = val_f.readlines()\n",
    "        val_f.close()\n",
    "\n",
    "        train_cids = []\n",
    "        for cid in train_caseids:\n",
    "            train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "        val_cids = []\n",
    "        for cid in val_caseids:\n",
    "            val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "        train_final = []\n",
    "        for i in range(len(list(data['Case_IDs'].values))):\n",
    "            resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "            if resu:\n",
    "                if resu.group(0) != '':\n",
    "                    train_final.append(i)\n",
    "\n",
    "        val_final = []\n",
    "        for j in range(len(list(data['Case_IDs'].values))):\n",
    "            resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[j])\n",
    "            if resu:\n",
    "                if resu.group(0) != '':\n",
    "                    val_final.append(j)\n",
    "\n",
    "        #train_final.insert(0, 1)\n",
    "        #val_final.insert(0, 1)\n",
    "        df_train = data.iloc[train_final,]\n",
    "        df_val = data.iloc[val_final,]\n",
    "\n",
    "        case_ids_val = df_val['Case_IDs']\n",
    "        #val_df_all = data_all[case_ids_val]\n",
    "        y_val = all_labels[case_ids_val].values\n",
    "        no_BDN_val = np.where(y_val != 'Blood Derived Normal')[0]\n",
    "        no_BDN_val = no_BDN_val.tolist()\n",
    "        df_val = df_val.iloc[no_BDN_val,:]\n",
    "        y_val = y_val[no_BDN_val]\n",
    "\n",
    "        #y_val = np.where(y_val == 'Blood Derived Normal', 'healthy', y_val)\n",
    "        y_val = np.where(y_val == 'Solid Tissue Normal', 'healthy', y_val)\n",
    "        y_val = np.where(y_val == 'LUAD', 'adeno', y_val)\n",
    "        y_val = np.where(y_val == 'LUSC', 'squa', y_val)\n",
    "\n",
    "        case_ids_train = df_train['Case_IDs']\n",
    "        #train_df_all = data_all[case_ids_train]\n",
    "        y_train = all_labels[case_ids_train].values\n",
    "        no_BDN_train = np.where(y_train != 'Blood Derived Normal')[0]\n",
    "        no_BDN_train = no_BDN_train.tolist()\n",
    "        df_train = df_train.iloc[no_BDN_train,:]\n",
    "        y_train = y_train[no_BDN_train]\n",
    "        #y_train = np.where(y_train == 'Blood Derived Normal', 'healthy', y_train)\n",
    "        y_train = np.where(y_train == 'Solid Tissue Normal', 'healthy', y_train)\n",
    "        y_train = np.where(y_train == 'LUAD', 'adeno', y_train)\n",
    "        y_train = np.where(y_train == 'LUSC', 'squa', y_train)\n",
    "\n",
    "        x_train = df_train.iloc[:,1:n_genes+1].values\n",
    "        x_val = df_val.iloc[:,1:n_genes+1].values\n",
    "        y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "        y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "        print('End data read...')\n",
    "\n",
    "        print('Svm training...')\n",
    "        tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                            'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "        clf = GridSearchCV(\n",
    "                        SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                    )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "        print(clf.best_params_)\n",
    "        best_params = clf.best_params_\n",
    "        train_preds = clf.predict(x_train)\n",
    "        corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "        train_acc = (corrects / x_train.shape[0]) * 100\n",
    "        train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted')\n",
    "        train_accs.append(train_acc)\n",
    "        train_F1.append(train_f1*100)\n",
    "        print('SVM train acc: {}'.format(train_acc))\n",
    "        print('SVM train F1: {}'.format(train_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds))\n",
    "\n",
    "        svm_ = SVC(**best_params)\n",
    "        #print(clf.best_params_)\n",
    "        x_val = scaler.transform(x_val)\n",
    "        test_preds = clf.predict(x_val)\n",
    "        corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "        test_acc = (corrects / x_val.shape[0]) * 100\n",
    "        test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted')\n",
    "        test_accs.append(test_acc)\n",
    "        test_F1.append(test_f1*100)\n",
    "        print('SVM test acc: {}'.format(test_acc))\n",
    "        print('SVM test F1: {}'.format(test_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds))\n",
    "    print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "    print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1),np.std(train_F1)))\n",
    "    print(10*'-')\n",
    "    print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "    print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1),np.std(test_F1)))\n",
    "    \n",
    "    global_train_accs['mean'].append(np.mean(train_accs))\n",
    "    global_test_accs['mean'].append(np.mean(test_accs))\n",
    "    global_train_f1['mean'].append(np.mean(train_F1))\n",
    "    global_test_f1['mean'].append(np.mean(test_F1))\n",
    "    global_train_accs['std'].append(np.std(train_accs))\n",
    "    global_test_accs['std'].append(np.std(test_accs))\n",
    "    global_train_f1['std'].append(np.std(train_F1))\n",
    "    global_test_f1['std'].append(np.std(test_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results for range of genes\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('Accuracy CNV NoBDN')\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('#genes')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.plot(list(range(1,16)), global_test_accs['mean'], color=\"blue\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('std')  # we already handled the x-label with ax1\n",
    "ax2.plot(list(range(1,16)), global_test_accs['std'], color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('plots/acc_range_p0-001_m0-1_cov3.png', format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Plot results for range of genes\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('F1 CNV NoBDN')\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('#genes')\n",
    "ax1.set_ylabel('F1-Score')\n",
    "ax1.plot(list(range(1,16)), global_test_f1['mean'], color=\"blue\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('std')  # we already handled the x-label with ax1\n",
    "ax2.plot(list(range(1,16)), global_test_f1['std'], color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('plots/f1_range_p0-001_m0-1_cov3.png', format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200.7px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
