{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0792ffba",
   "metadata": {},
   "source": [
    "# RNA-Seq classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f44c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rna = pd.read_csv('../RNA-Seq/RNA-ExpAll-LC.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['healthy', 'adeno', 'squa'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, x_test, y_train_ohe, y_test_ohe, accs, f1s, name, early=False, verbose=False):\n",
    "    \n",
    "    tuned_parameters = [{'max_depth': [2, 4, 6, 8],\n",
    "                            'n_estimators': [20, 30, 50, 100, 200],\n",
    "                         'alpha': [0,0.1,0.2,0.3]}]\n",
    "    \n",
    "    \n",
    "    clf = GridSearchCV(\n",
    "                    xgb.XGBClassifier(n_jobs=1,use_label_encoder=False,verbosity = 0, random_state=42), tuned_parameters, \n",
    "                    scoring='accuracy'\n",
    "                )\n",
    "    if early:\n",
    "        classes_ = [0,1,2]\n",
    "        x_train_new, y_train_ohe_new, x_val, y_val = get_val_set(x_train, y_train_ohe, classes_, percentage = 0.1)\n",
    "    else:\n",
    "        x_train_new = x_train\n",
    "        y_train_ohe_new = y_train_ohe\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_train_new = scaler.fit_transform(x_train_new)\n",
    "    if early:\n",
    "        eval_set=[(scaler.transform(x_val), y_val.argmax(axis=1))]\n",
    "        clf.fit(x_train_new, y_train_ohe_new.argmax(axis=1), early_stopping_rounds=10, eval_set=eval_set, verbose=False)\n",
    "    else:\n",
    "        clf.fit(x_train_new, y_train_ohe_new.argmax(axis=1))\n",
    "    print(clf.best_params_)\n",
    "    best_params = clf.best_params_\n",
    "    train_preds = clf.predict(scaler.transform(x_train))\n",
    "    corrects = np.sum(train_preds == y_train_ohe_new.argmax(axis=1))\n",
    "    train_acc = (corrects / x_train_new.shape[0]) * 100\n",
    "    train_f1 = f1_score(y_train_ohe_new.argmax(axis=1), train_preds, average='weighted')\n",
    "    accs['train'][name].append(train_acc)\n",
    "    f1s['train'][name].append(train_f1)\n",
    "    train_probs = clf.predict_proba(x_train_new)\n",
    "    if verbose:\n",
    "        print('Train acc: {}'.format(train_acc))\n",
    "        print('Train F1: {}'.format(train_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_train_ohe_new.argmax(axis=1), train_preds))\n",
    "\n",
    "    #svm_ = SVC(**best_params)\n",
    "    #print(clf.best_params_)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    test_preds = clf.predict(x_test)\n",
    "    corrects = np.sum(test_preds == y_test_ohe.argmax(axis=1))\n",
    "    test_acc = (corrects / x_test.shape[0]) * 100\n",
    "    test_f1 = f1_score(y_test_ohe.argmax(axis=1), test_preds, average='weighted')\n",
    "    accs['test'][name].append(test_acc)\n",
    "    f1s['test'][name].append(test_f1)\n",
    "    test_probs = clf.predict_proba(x_test)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Test acc: {}'.format(test_acc))\n",
    "        print('Test F1: {}'.format(test_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_test_ohe.argmax(axis=1), test_preds))\n",
    "    \n",
    "    probs = {\n",
    "        'train': train_probs,\n",
    "        'test': test_probs\n",
    "    }\n",
    "    preds = {\n",
    "        'train': train_preds,\n",
    "        'test': test_preds\n",
    "    }\n",
    "    return accs, f1s, probs, preds\n",
    "\n",
    "def get_val_set(x, y, classes, percentage = 0.1):\n",
    "    np.random.seed(42)  \n",
    "    x_train = np.array([]).reshape(0,x.shape[1])\n",
    "    y_train = np.array([]).reshape(0,y.shape[1])\n",
    "    x_val = np.array([]).reshape(0,x.shape[1])\n",
    "    y_val = np.array([]).reshape(0,y.shape[1])\n",
    "    for c in classes:\n",
    "        indexes = np.where(y.argmax(axis=1) == c)[0]\n",
    "        np.random.shuffle(indexes)\n",
    "        len_val = int(percentage * len(indexes))\n",
    "        len_train = len(indexes) - len_val\n",
    "        index_train = indexes[0:len_train]\n",
    "        index_val = indexes[len_train:]\n",
    "        x_train = np.concatenate([x_train, x[index_train,...]], axis=0)\n",
    "        y_train = np.concatenate([y_train, y[index_train]], axis=0)\n",
    "        x_val = np.concatenate([x_val, x[index_val,...]], axis=0)\n",
    "        y_val = np.concatenate([y_val, y[index_val]], axis=0)\n",
    "    \n",
    "    index_train = list(range(x_train.shape[0]))\n",
    "    index_val = list(range(x_val.shape[0]))\n",
    "    np.random.shuffle(index_train)\n",
    "    np.random.shuffle(index_val)\n",
    "    \n",
    "    return x_train[index_train,...],y_train[index_train], x_val[index_val,...], y_val[index_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2be074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import re\n",
    "path = '../Copy-Number-Variation/Splits_10CV/'\n",
    "path_rna_mrmr = 'mrmrDEGs/'\n",
    "\n",
    "n_genes = 6\n",
    "writer_test = pd.ExcelWriter('results_excels/RNA_'+str(n_genes)+'gen_test_XGBoost.xlsx', engine='openpyxl') \n",
    "writer_train = pd.ExcelWriter('results_excels/RNA_'+str(n_genes)+'gen_train_XGBoost.xlsx', engine='openpyxl') \n",
    "\n",
    "accs = {\n",
    "    'train': {'RNA': []},\n",
    "    'test': {'RNA': []}\n",
    "}\n",
    "f1s = {\n",
    "    'train': {'RNA': []},\n",
    "    'test': {'RNA': []}\n",
    "}\n",
    "\n",
    "name = 'RNA'\n",
    "for split in range(10):\n",
    "    print(10*'-')\n",
    "    print('Split {}/{}'.format(split,10))\n",
    "    print(10*'-')\n",
    "    \n",
    "    print('Data read...')\n",
    "    data = pd.read_csv(path_rna_mrmr+'mrmrDEGs_LC_3classes_split'+str(split)+'.csv')\n",
    "    \n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for j in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[j])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(j)\n",
    "\n",
    "    #train_final.insert(0, 1)\n",
    "    #val_final.insert(0, 1)\n",
    "    df_train = data.iloc[train_final,]\n",
    "    df_val = data.iloc[val_final,]\n",
    "\n",
    "    case_ids_val = df_val['Case_IDs']\n",
    "    #val_df_all = data_all[case_ids_val]\n",
    "    y_val = all_rna['labelsAll'].loc[all_rna['Case_IDs'].isin(case_ids_val)].values\n",
    "    #y_val = np.where(y_val == 'Blood Derived Normal', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Healthy', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'Adenocarcinoma', 'adeno', y_val)\n",
    "    y_val = np.where(y_val == 'Squamous', 'squa', y_val)\n",
    "    \n",
    "    case_ids_train = df_train['Case_IDs']\n",
    "    #train_df_all = data_all[case_ids_train]\n",
    "    y_train = all_rna['labelsAll'].loc[all_rna['Case_IDs'].isin(case_ids_train)].values\n",
    "    #y_train = np.where(y_train == 'Blood Derived Normal', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Healthy', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'Adenocarcinoma', 'adeno', y_train)\n",
    "    y_train = np.where(y_train == 'Squamous', 'squa', y_train)\n",
    "    \n",
    "    x_train = df_train.iloc[:,1:n_genes+1].values\n",
    "    x_val = df_val.iloc[:,1:n_genes+1].values\n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "    print('End data read...')\n",
    "    \n",
    "    print('Training...')\n",
    "    accs, f1s, probs, preds = train(x_train, x_val, y_train_ohe, y_val_ohe, accs, f1s, name, early=False, verbose=False)\n",
    "    \n",
    "    print(\"Saving SVM predictions... \\n\")\n",
    "    \n",
    "    sheet_name = 'split_'+str(split)\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_val\n",
    "    data['Preds'] = preds['test']\n",
    "    data['Prob LUAD'] = probs['test'][:, 0]\n",
    "    data['Prob HLT'] = probs['test'][:, 1]\n",
    "    data['Prob LUSC'] = probs['test'][:, 2]\n",
    "    data['Real'] = y_val_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_test, sheet_name = sheet_name)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_train\n",
    "    data['Preds'] = preds['train']\n",
    "    data['Prob LUAD'] = probs['train'][:, 0]\n",
    "    data['Prob HLT'] = probs['train'][:, 1]\n",
    "    data['Prob LUSC'] = probs['train'][:, 2]\n",
    "    data['Real'] = y_train_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_train, sheet_name=sheet_name)\n",
    "\n",
    "writer_train.close()\n",
    "writer_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c893c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Acc in train: {}+-{}'.format(np.mean(accs['train']['RNA']),np.std(accs['train']['RNA'])))\n",
    "print('Mean F1 in train: {}+-{}'.format(np.mean(f1s['train']['RNA'])*100,np.std(f1s['train']['RNA'])*100))\n",
    "print(10*'-')\n",
    "print('Mean Acc in test: {}+-{}'.format(np.mean(accs['test']['RNA']),np.std(accs['test']['RNA'])))\n",
    "print('Mean F1 in test: {}+-{}'.format(np.mean(f1s['test']['RNA'])*100,np.std(f1s['test']['RNA'])*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
