{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('CpGs_450_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"TCGA-44-2656-01A\"]\n",
    "\n",
    "data = data.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('CpGs_450_matrix_nonans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CpGs_450_matrix_nonans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Splits_10CV_miRNA/'\n",
    "for split in range(1,10):\n",
    "    print('{}/{}'.format(split,9))\n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "        \n",
    "    train_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(train_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for i in range(len(list(data.columns))):\n",
    "        resu = re.match('|'.join(val_cids),list(data.columns)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(i)\n",
    "\n",
    "    train_final.insert(0, 0)\n",
    "    val_final.insert(0, 0)\n",
    "    df_train = data.iloc[:,train_final]\n",
    "    df_val = data.iloc[:,val_final]\n",
    "    labels_train = df_train.iloc[-1,:].values\n",
    "    hlt_idx = np.where(labels_train == 'Healthy')[0]\n",
    "    luad_idx = np.where(labels_train == 'LUAD')[0]\n",
    "    lusc_idx = np.where(labels_train == 'LUSC')[0]\n",
    "    \n",
    "    # p-values and means\n",
    "    p_value_hltluad = []\n",
    "    p_value_hltlusc = []\n",
    "    p_value_luscluad = []\n",
    "    mean_dif_hltluad = []\n",
    "    mean_dif_hltlusc = []\n",
    "    mean_dif_luscluad = []\n",
    "    for _, row in tqdm(df_train.iterrows()):\n",
    "        if row[0] == 'Label':\n",
    "            continue\n",
    "        comp_counter = 0\n",
    "\n",
    "        hlt = row[hlt_idx].to_numpy(dtype='float')\n",
    "        luad = row[luad_idx].to_numpy(dtype='float')\n",
    "        lusc = row[lusc_idx].to_numpy(dtype='float')\n",
    "\n",
    "        stats_hltluad = stats.ttest_ind(hlt,luad,equal_var=False)\n",
    "        stats_hltlusc = stats.ttest_ind(hlt,lusc,equal_var=False)\n",
    "        stats_luscluad = stats.ttest_ind(lusc,luad,equal_var=False)\n",
    "\n",
    "        mean_dif_hltluad.append(np.abs(np.mean(hlt) - np.mean(luad)))\n",
    "        mean_dif_hltlusc.append(np.abs(np.mean(hlt) - np.mean(lusc)))\n",
    "        mean_dif_luscluad.append(np.abs(np.mean(lusc) - np.mean(luad)))\n",
    "\n",
    "        p_value_hltluad.append(stats_hltluad.pvalue)\n",
    "        p_value_hltlusc.append(stats_hltlusc.pvalue)\n",
    "        p_value_luscluad.append(stats_luscluad.pvalue)\n",
    "    \n",
    "    p_values_df = pd.DataFrame()\n",
    "    p_values_df['CpGs'] = df_train['CpGs'].values[:-1]\n",
    "    p_values_df['HltLusc'] = p_value_hltlusc\n",
    "    p_values_df['HltLuad'] = p_value_hltluad\n",
    "    p_values_df['LuscLuad'] = p_value_luscluad\n",
    "    p_values_df['MeanHltLuad'] = mean_dif_hltluad\n",
    "    p_values_df['MeanHltLusc'] = mean_dif_hltlusc\n",
    "    p_values_df['MeanLuscLuad'] = mean_dif_luscluad\n",
    "\n",
    "    p_values_df.to_csv('p-values-matrix/p_values_train'+str(split)+'.csv', index=False)\n",
    "    decpgs = []\n",
    "    for _, row in tqdm(p_values_df.iterrows()):\n",
    "        comp_counter = 0\n",
    "        if row['HltLuad'] <= 0.001/3 and row['MeanHltLuad'] >= 0.4:\n",
    "                comp_counter += 1\n",
    "        if row['HltLusc'] <= 0.001/3 and row['MeanHltLusc'] >= 0.4:\n",
    "            comp_counter += 1\n",
    "        if row['LuscLuad'] <= 0.001/3 and row['MeanLuscLuad'] >= 0.4:\n",
    "            comp_counter += 1\n",
    "\n",
    "        if comp_counter == 2:\n",
    "            decpgs.append(row[0])\n",
    "    \n",
    "    decpgs.append('Label')\n",
    "    \n",
    "    train_degs = df_train.loc[df_train['CpGs'].isin(decpgs)]\n",
    "    train_degs.to_csv('train_degs/CpGs_DE_train'+str(split)+'_p0-001_cov2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('p-values-matrix')\n",
    "os.mkdir('train_degs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = []\n",
    "for i in range(len(list(data.columns))):\n",
    "    resu = re.match('|'.join(train_cids),list(data.columns)[i])\n",
    "    if resu:\n",
    "        if resu.group(0) != '':\n",
    "            train_final.append(i)\n",
    "\n",
    "val_final = []\n",
    "for i in range(len(list(data.columns))):\n",
    "    resu = re.match('|'.join(val_cids),list(data.columns)[i])\n",
    "    if resu:\n",
    "        if resu.group(0) != '':\n",
    "            val_final.append(i)\n",
    "\n",
    "train_final.insert(0, 0)\n",
    "val_final.insert(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.iloc[:,train_final]\n",
    "df_val = data.iloc[:,val_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = df_train.iloc[-1,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlt_idx = np.where(labels_train == 'Healthy')[0]\n",
    "luad_idx = np.where(labels_train == 'LUAD')[0]\n",
    "lusc_idx = np.where(labels_train == 'LUSC')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_hltluad = []\n",
    "p_value_hltlusc = []\n",
    "p_value_luscluad = []\n",
    "mean_dif_hltluad = []\n",
    "mean_dif_hltlusc = []\n",
    "mean_dif_luscluad = []\n",
    "for _, row in tqdm(df_train.iterrows()):\n",
    "    if row[0] == 'Label':\n",
    "        continue\n",
    "    comp_counter = 0\n",
    "    \n",
    "    hlt = row[hlt_idx].to_numpy(dtype='float')\n",
    "    luad = row[luad_idx].to_numpy(dtype='float')\n",
    "    lusc = row[lusc_idx].to_numpy(dtype='float')\n",
    "    \n",
    "    stats_hltluad = stats.ttest_ind(hlt,luad,equal_var=False)\n",
    "    stats_hltlusc = stats.ttest_ind(hlt,lusc,equal_var=False)\n",
    "    stats_luscluad = stats.ttest_ind(lusc,luad,equal_var=False)\n",
    "    \n",
    "    mean_dif_hltluad.append(np.abs(np.mean(hlt) - np.mean(luad)))\n",
    "    mean_dif_hltlusc.append(np.abs(np.mean(hlt) - np.mean(lusc)))\n",
    "    mean_dif_luscluad.append(np.abs(np.mean(lusc) - np.mean(luad)))\n",
    "    \n",
    "    p_value_hltluad.append(stats_hltluad.pvalue)\n",
    "    p_value_hltlusc.append(stats_hltlusc.pvalue)\n",
    "    p_value_luscluad.append(stats_luscluad.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = pd.DataFrame()\n",
    "p_values_df['CpGs'] = df_train['CpGs'].values[:-1]\n",
    "p_values_df['HltLusc'] = p_value_hltlusc\n",
    "p_values_df['HltLuad'] = p_value_hltluad\n",
    "p_values_df['LuscLuad'] = p_value_luscluad\n",
    "p_values_df['MeanHltLuad'] = mean_dif_hltluad\n",
    "p_values_df['MeanHltLusc'] = mean_dif_hltlusc\n",
    "p_values_df['MeanLuscLuad'] = mean_dif_luscluad\n",
    "\n",
    "p_values_df.to_csv('p_values_train0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = pd.read_csv('p_values_train0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decpgs = []\n",
    "for _, row in tqdm(p_values_df.iterrows()):\n",
    "    comp_counter = 0\n",
    "    if row['HltLuad'] <= 0.001/3 and row['MeanHltLuad'] >= 0.4:\n",
    "            comp_counter += 1\n",
    "    if row['HltLusc'] <= 0.001/3 and row['MeanHltLusc'] >= 0.4:\n",
    "        comp_counter += 1\n",
    "    if row['LuscLuad'] <= 0.001/3 and row['MeanLuscLuad'] >= 0.4:\n",
    "        comp_counter += 1\n",
    "\n",
    "    if comp_counter == 2:\n",
    "        decpgs.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decpgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decpgs.append('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_degs = df_train.loc[data['CpGs'].isin(decpgs)]\n",
    "train_degs.to_csv('CpGs_DE_train0_p0-001_cov2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_degs = pd.DataFrame(columns = train_degs['CpGs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_degs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_degs = df_val.loc[data['CpGs'].isin(decpgs)]\n",
    "val_degs.to_csv('CpGs_DE_val0_p0-001_cov2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrmrCpG = [\"cg03555299\", \"cg08566455\", \"cg27649037\", \n",
    "\"cg06188545\", \"cg17283169\", \"cg14294859\",\n",
    "\"cg18121066\", \"cg24597774\", \"cg03502002\",\n",
    "\"cg11201447\", \"cg12222244\", \"cg00074145\", \n",
    "\"cg17510385\", \"cg16759976\", \"cg16404371\", \n",
    "\"cg00415665\", \"cg14557064\", \"cg25521254\", \n",
    "\"cg23746497\", \"cg27071152\", \"cg25115460\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "classes = np.array(['Healthy', 'LUAD', 'LUSC'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_degs_T = train_degs.transpose()\n",
    "train_degs_T.columns = train_degs_T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_degs_T = val_degs.transpose()\n",
    "val_degs_T = val_degs_T.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_degs_T.loc[:,mrmrCpG[0:7]].values, train_degs_T.loc[:,'Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = val_degs_T.loc[:,mrmrCpG[0:7]].values, val_degs_T.loc[:,'Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "y_test_ohe = ohe.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "clf = GridSearchCV(\n",
    "                SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "            )\n",
    "\n",
    "clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "print(clf.best_params_)\n",
    "best_params = clf.best_params_\n",
    "train_preds = clf.predict(x_train)\n",
    "corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "train_acc = (corrects / x_train.shape[0]) * 100\n",
    "print('kNN train acc: {}'.format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_ = SVC(**best_params)\n",
    "#print(clf.best_params_)\n",
    "test_preds = clf.predict(x_test)\n",
    "corrects = np.sum(test_preds == y_test_ohe.argmax(axis=1))\n",
    "test_acc = (corrects / x_test.shape[0]) * 100\n",
    "print('kNN test acc: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('CpGs_450_matrix_nonans.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "classes = np.array(['adeno', 'squa', 'healthy'])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe.fit(classes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(np.array(['adeno']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('results_excels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "path = 'Splits_10CV/'\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "train_F1 = []\n",
    "test_F1 = []\n",
    "\n",
    "n_cpgs = 6\n",
    "writer_test = pd.ExcelWriter('results_excels/DNA-Methylation'+str(n_cpgs)+'CpGs_test.xlsx', engine='openpyxl') \n",
    "writer_train = pd.ExcelWriter('results_excels/DNA-Methylation'+str(n_cpgs)+'CpGs_train.xlsx', engine='openpyxl') \n",
    "all_labels = data_all.iloc[-1,:]\n",
    "for split in range(10):\n",
    "    print(10*'-')\n",
    "    print('Split {}/{}'.format(split,10))\n",
    "    print(10*'-')\n",
    "    \n",
    "    print('Data read...')\n",
    "    data = pd.read_csv('mrmrCpGs/mrmrCpGs_LC_DNA_3classes_split'+str(split)+'.csv')\n",
    "    train_f = open(path+'train_'+str(split)+'.txt', 'r')\n",
    "    train_caseids = train_f.readlines()\n",
    "    train_f.close()\n",
    "    val_f = open(path+'val_'+str(split)+'.txt', 'r')\n",
    "    val_caseids = val_f.readlines()\n",
    "    val_f.close()\n",
    "\n",
    "    train_cids = []\n",
    "    for cid in train_caseids:\n",
    "        train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "    val_cids = []\n",
    "    for cid in val_caseids:\n",
    "        val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "    train_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                train_final.append(i)\n",
    "\n",
    "    val_final = []\n",
    "    for i in range(len(list(data['Case_IDs'].values))):\n",
    "        resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[i])\n",
    "        if resu:\n",
    "            if resu.group(0) != '':\n",
    "                val_final.append(i)\n",
    "    \n",
    "    train_final.insert(0, 1)\n",
    "    val_final.insert(0, 1)\n",
    "    df_train = data.iloc[train_final,]\n",
    "    df_val = data.iloc[val_final,]\n",
    "    case_ids_val = df_val['Case_IDs']\n",
    "    #val_df_all = data_all[case_ids_val]\n",
    "    y_val = all_labels[case_ids_val].values\n",
    "    y_val = np.where(y_val == 'Healthy', 'healthy', y_val)\n",
    "    y_val = np.where(y_val == 'LUAD', 'adeno', y_val)\n",
    "    y_val = np.where(y_val == 'LUSC', 'squa', y_val)\n",
    "    \n",
    "    case_ids_train = df_train['Case_IDs']\n",
    "    #train_df_all = data_all[case_ids_train]\n",
    "    y_train = all_labels[case_ids_train].values\n",
    "    y_train = np.where(y_train == 'Healthy', 'healthy', y_train)\n",
    "    y_train = np.where(y_train == 'LUAD', 'adeno', y_train)\n",
    "    y_train = np.where(y_train == 'LUSC', 'squa', y_train)\n",
    "    \n",
    "    x_train = df_train.iloc[:,1:n_cpgs+1].values\n",
    "    x_val = df_val.iloc[:,1:n_cpgs+1].values\n",
    "    y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "    y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                        'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "    clf = GridSearchCV(\n",
    "                    SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                )\n",
    "    print('End data read...')\n",
    "    \n",
    "    #scaler = StandardScaler()\n",
    "    #x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "    #### SVM TRAINING\n",
    "    print('Svm training...')\n",
    "    clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "    print(clf.best_params_)\n",
    "    best_params = clf.best_params_\n",
    "    train_preds = clf.predict(x_train)\n",
    "    corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "    train_acc = (corrects / x_train.shape[0]) * 100\n",
    "    train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted')\n",
    "    train_accs.append(train_acc)\n",
    "    train_F1.append(train_f1*100)\n",
    "    train_probs = clf.predict_proba(x_train)\n",
    "    print('SVM train acc: {}'.format(train_acc))\n",
    "    print('SVM train F1: {}'.format(train_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds))\n",
    "    \n",
    "    #### SVM TEST\n",
    "    svm_ = SVC(**best_params)\n",
    "    #print(clf.best_params_)\n",
    "    #x_val = scaler.transform(x_val)\n",
    "    test_preds = clf.predict(x_val)\n",
    "    corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "    test_acc = (corrects / x_val.shape[0]) * 100\n",
    "    test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted')\n",
    "    test_accs.append(test_acc)\n",
    "    test_F1.append(test_f1*100)\n",
    "    test_probs = clf.predict_proba(x_val)\n",
    "    print('SVM test acc: {}'.format(test_acc))\n",
    "    print('SVM test F1: {}'.format(test_f1))\n",
    "    print('CM \\n')\n",
    "    print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds))\n",
    "    \n",
    "    #### SVM SAVE PREDS\n",
    "    print(\"Saving SVM predictions... \\n\")\n",
    "    \n",
    "    sheet_name = 'split_'+str(split)\n",
    "    \n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_val\n",
    "    data['Preds'] = test_preds\n",
    "    data['Prob LUAD'] = test_probs[:, 0]\n",
    "    data['Prob HLT'] = test_probs[:, 1]\n",
    "    data['Prob LUSC'] = test_probs[:, 2]\n",
    "    data['Real'] = y_val_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_test, sheet_name = sheet_name)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['Case_Ids'] = case_ids_train\n",
    "    data['Preds'] = train_preds\n",
    "    data['Prob LUAD'] = train_probs[:, 0]\n",
    "    data['Prob HLT'] = train_probs[:, 1]\n",
    "    data['Prob LUSC'] = train_probs[:, 2]\n",
    "    data['Real'] = y_train_ohe.argmax(axis=1)\n",
    "    data.to_excel(writer_train, sheet_name=sheet_name)\n",
    "\n",
    "writer_train.close()\n",
    "writer_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1),np.std(train_F1)))\n",
    "print(10*'-')\n",
    "print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1),np.std(test_F1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "X_embedded = TSNE(n_components=2).fit_transform(x_val)\n",
    "\n",
    "hlt = np.where(y_val == 'Healthy')[0]\n",
    "luad = np.where(y_val == 'LUAD')[0]\n",
    "lusc = np.where(y_val == 'LUSC')[0]\n",
    "\n",
    "X_embedded_hlt = X_embedded[hlt,:]\n",
    "X_embedded_luad = X_embedded[luad,:]\n",
    "X_embedded_lusc = X_embedded[lusc,:]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_embedded_hlt[:, 0], X_embedded_hlt[:, 1], c='blue', label='HLT')\n",
    "plt.scatter(X_embedded_luad[:, 0], X_embedded_luad[:, 1], c='green', label='LUAD')\n",
    "plt.scatter(X_embedded_lusc[:, 0], X_embedded_lusc[:, 1], c='red', label='LUSC')\n",
    "plt.legend()\n",
    "plt.savefig('plots/tsne_lastfold_cov2.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test optimal number of CpGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "# All range of genes results\n",
    "path = 'Splits_10CV/'\n",
    "\n",
    "\n",
    "range_cpgs = 17\n",
    "all_labels = data_all.iloc[-1,:]\n",
    "global_train_accs = {'mean':[],'std':[]}\n",
    "global_test_accs = {'mean':[],'std':[]}\n",
    "global_train_f1 = {'mean':[],'std':[]}\n",
    "global_test_f1 = {'mean':[],'std':[]}\n",
    "for n_cpgs in trange(1,range_cpgs):\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    train_F1 = []\n",
    "    test_F1 = []\n",
    "    for i in range(10):\n",
    "        print(10*'-')\n",
    "        print('Split {}/{}'.format(i,10))\n",
    "        print(10*'-')\n",
    "\n",
    "        print('Data read...')\n",
    "        data = pd.read_csv('mrmrCpGs/mrmrCpGs_LC_DNA_3classes_split'+str(i)+'.csv')\n",
    "\n",
    "        train_f = open(path+'train_'+str(i)+'.txt', 'r')\n",
    "        train_caseids = train_f.readlines()\n",
    "        train_f.close()\n",
    "        val_f = open(path+'val_'+str(i)+'.txt', 'r')\n",
    "        val_caseids = val_f.readlines()\n",
    "        val_f.close()\n",
    "\n",
    "        train_cids = []\n",
    "        for cid in train_caseids:\n",
    "            train_cids.append(cid.replace('\\n', ''))\n",
    "\n",
    "        val_cids = []\n",
    "        for cid in val_caseids:\n",
    "            val_cids.append(cid.replace('\\n', '')) \n",
    "\n",
    "        train_final = []\n",
    "        for i in range(len(list(data['Case_IDs'].values))):\n",
    "            resu = re.match('|'.join(train_cids),list(data['Case_IDs'].values)[i])\n",
    "            if resu:\n",
    "                if resu.group(0) != '':\n",
    "                    train_final.append(i)\n",
    "\n",
    "        val_final = []\n",
    "        for i in range(len(list(data['Case_IDs'].values))):\n",
    "            resu = re.match('|'.join(val_cids),list(data['Case_IDs'].values)[i])\n",
    "            if resu:\n",
    "                if resu.group(0) != '':\n",
    "                    val_final.append(i)\n",
    "\n",
    "        #train_final.insert(0, 1)\n",
    "        #val_final.insert(0, 1)\n",
    "        df_train = data.iloc[train_final,]\n",
    "        df_val = data.iloc[val_final,]\n",
    "\n",
    "        case_ids_val = df_val['Case_IDs']\n",
    "        #val_df_all = data_all[case_ids_val]\n",
    "        y_val = all_labels[case_ids_val].values\n",
    "        y_val = np.where(y_val == 'Healthy', 'healthy', y_val)\n",
    "        y_val = np.where(y_val == 'LUAD', 'adeno', y_val)\n",
    "        y_val = np.where(y_val == 'LUSC', 'squa', y_val)\n",
    "\n",
    "        case_ids_train = df_train['Case_IDs']\n",
    "        #train_df_all = data_all[case_ids_train]\n",
    "        y_train = all_labels[case_ids_train].values\n",
    "        y_train = np.where(y_train == 'Healthy', 'healthy', y_train)\n",
    "        y_train = np.where(y_train == 'LUAD', 'adeno', y_train)\n",
    "        y_train = np.where(y_train == 'LUSC', 'squa', y_train)\n",
    "\n",
    "        x_train = df_train.iloc[:,1:n_cpgs+1].values\n",
    "        x_val = df_val.iloc[:,1:n_cpgs+1].values\n",
    "        y_train_ohe = ohe.transform(y_train.reshape(-1,1))\n",
    "        y_val_ohe = ohe.transform(y_val.reshape(-1,1))\n",
    "        print('End data read...')\n",
    "\n",
    "        print('Svm training...')\n",
    "        tuned_parameters = [{'kernel': ['rbf'], 'gamma': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7],\n",
    "                            'C': [2**-7, 2**-5, 2**-2, 2, 2**4, 2**7]}]\n",
    "        clf = GridSearchCV(\n",
    "                        SVC(probability=True), tuned_parameters, scoring='accuracy'\n",
    "                    )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        clf.fit(x_train, y_train_ohe.argmax(axis=1))\n",
    "        print(clf.best_params_)\n",
    "        best_params = clf.best_params_\n",
    "        train_preds = clf.predict(x_train)\n",
    "        corrects = np.sum(train_preds == y_train_ohe.argmax(axis=1))\n",
    "        train_acc = (corrects / x_train.shape[0]) * 100\n",
    "        train_f1 = f1_score(y_train_ohe.argmax(axis=1), train_preds, average='weighted', labels=[1, 0, 2])\n",
    "        train_accs.append(train_acc)\n",
    "        train_F1.append(train_f1*100)\n",
    "        print('SVM train acc: {}'.format(train_acc))\n",
    "        print('SVM train F1: {}'.format(train_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_train_ohe.argmax(axis=1), train_preds, labels=[1, 0, 2]))\n",
    "\n",
    "        svm_ = SVC(**best_params)\n",
    "        #print(clf.best_params_)\n",
    "        x_val = scaler.transform(x_val)\n",
    "        test_preds = clf.predict(x_val)\n",
    "        corrects = np.sum(test_preds == y_val_ohe.argmax(axis=1))\n",
    "        test_acc = (corrects / x_val.shape[0]) * 100\n",
    "        test_f1 = f1_score(y_val_ohe.argmax(axis=1), test_preds, average='weighted', labels=[1, 0, 2])\n",
    "        test_accs.append(test_acc)\n",
    "        test_F1.append(test_f1*100)\n",
    "        print('SVM test acc: {}'.format(test_acc))\n",
    "        print('SVM test F1: {}'.format(test_f1))\n",
    "        print('CM \\n')\n",
    "        print(confusion_matrix(y_val_ohe.argmax(axis=1), test_preds,labels=[1, 0, 2]))\n",
    "    print('Mean Acc in train: {}+-{}'.format(np.mean(train_accs),np.std(train_accs)))\n",
    "    print('Mean F1 in train: {}+-{}'.format(np.mean(train_F1),np.std(train_F1)))\n",
    "    print(10*'-')\n",
    "    print('Mean Acc in test: {}+-{}'.format(np.mean(test_accs),np.std(test_accs)))\n",
    "    print('Mean F1 in test: {}+-{}'.format(np.mean(test_F1),np.std(test_F1)))\n",
    "    \n",
    "    global_train_accs['mean'].append(np.mean(train_accs))\n",
    "    global_test_accs['mean'].append(np.mean(test_accs))\n",
    "    global_train_f1['mean'].append(np.mean(train_F1))\n",
    "    global_test_f1['mean'].append(np.mean(test_F1))\n",
    "    global_train_accs['std'].append(np.std(train_accs))\n",
    "    global_test_accs['std'].append(np.std(test_accs))\n",
    "    global_train_f1['std'].append(np.std(train_F1))\n",
    "    global_test_f1['std'].append(np.std(test_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results for range of genes\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('Accuracy DNA Methy')\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('#CpGs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.plot(list(range(1,16)), global_test_accs['mean'], color=\"blue\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('std')  # we already handled the x-label with ax1\n",
    "ax2.plot(list(range(1,16)), global_test_accs['std'], color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig('plots/acc_range_dna_cov2.png', format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Plot results for range of genes\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('F1 DNA Methy')\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('#gCpGs')\n",
    "ax1.set_ylabel('F1-Score')\n",
    "ax1.plot(list(range(1,16)), global_test_f1['mean'], color=\"blue\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('std')  # we already handled the x-label with ax1\n",
    "ax2.plot(list(range(1,16)), global_test_f1['std'], color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.savefig('plots/f1_range_dna_cov2.png', format='png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
